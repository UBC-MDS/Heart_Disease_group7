{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n"]},{"cell_type":"markdown","metadata":{},"source":["## Data Labels\n","\n","1. **age**: Age in years  \n","2. **sex**: Sex  \n","   - `1` = Male  \n","   - `0` = Female  \n","3. **cp**: Chest pain type  \n","   - Value `1`: Typical angina  \n","   - Value `2`: Atypical angina  \n","   - Value `3`: Non-anginal pain  \n","   - Value `4`: Asymptomatic  \n","4. **trestbps**: Resting blood pressure (in mm Hg on admission to the hospital)  \n","5. **chol**: Serum cholesterol in mg/dl  \n","6. **fbs**: Fasting blood sugar (> 120 mg/dl)  \n","   - `1` = True  \n","   - `0` = False  \n","7. **restecg**: Resting electrocardiographic results  \n","   - Value `0`: Normal  \n","   - Value `1`: Having ST-T wave abnormality (T wave inversions and/or ST  \n","     elevation or depression of > 0.05 mV)  \n","   - Value `2`: Showing probable or definite left ventricular hypertrophy by  \n","     Estes' criteria  \n","8. **thalach**: Maximum heart rate achieved  \n","9. **exang**: Exercise-induced angina  \n","   - `1` = Yes  \n","   - `0` = No  \n","10. **oldpeak**: ST depression induced by exercise relative to rest  \n","11. **slope**: The slope of the peak exercise ST segment  \n","    - Value `1`: Upsloping  \n","    - Value `2`: Flat  \n","    - Value `3`: Downsloping  \n","12. **ca**: Number of major vessels (0-3) colored by fluoroscopy  \n","13. **thal**:  \n","    - `3` = Normal  \n","    - `6` = Fixed defect  \n","    - `7` = Reversible defect"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["columns = ['age','sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'label']"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["hungary_df = pd.read_csv('data/processed.hungarian.data',index_col=False, names = columns)\n","swiss_df = pd.read_csv('data/processed.switzerland.data',index_col=False, names = columns)\n","cleveland_df = pd.read_csv('data/processed.cleveland.data',index_col=False, names = columns)\n","va_df = pd.read_csv('data/processed.va.data',index_col=False, names = columns)\n","\n","combined_df = pd.concat([hungary_df, swiss_df, cleveland_df, va_df], axis = 0)\n"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>sex</th>\n","      <th>cp</th>\n","      <th>trestbps</th>\n","      <th>chol</th>\n","      <th>fbs</th>\n","      <th>restecg</th>\n","      <th>thalach</th>\n","      <th>exang</th>\n","      <th>oldpeak</th>\n","      <th>slope</th>\n","      <th>ca</th>\n","      <th>thal</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>28.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>130</td>\n","      <td>132</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>185</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>?</td>\n","      <td>?</td>\n","      <td>?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>29.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>120</td>\n","      <td>243</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>160</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>?</td>\n","      <td>?</td>\n","      <td>?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>29.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>140</td>\n","      <td>?</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>170</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>?</td>\n","      <td>?</td>\n","      <td>?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>30.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>170</td>\n","      <td>237</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>170</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>?</td>\n","      <td>?</td>\n","      <td>6</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>31.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>100</td>\n","      <td>219</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>150</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>?</td>\n","      <td>?</td>\n","      <td>?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>32.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>105</td>\n","      <td>198</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>165</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>?</td>\n","      <td>?</td>\n","      <td>?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>32.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>110</td>\n","      <td>225</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>184</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>?</td>\n","      <td>?</td>\n","      <td>?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>32.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>125</td>\n","      <td>254</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>155</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>?</td>\n","      <td>?</td>\n","      <td>?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>33.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>120</td>\n","      <td>298</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>185</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>?</td>\n","      <td>?</td>\n","      <td>?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>34.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>130</td>\n","      <td>161</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>190</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>?</td>\n","      <td>?</td>\n","      <td>?</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    age  sex   cp trestbps chol fbs restecg thalach exang oldpeak slope ca  \\\n","0  28.0  1.0  2.0      130  132   0       2     185     0     0.0     ?  ?   \n","1  29.0  1.0  2.0      120  243   0       0     160     0     0.0     ?  ?   \n","2  29.0  1.0  2.0      140    ?   0       0     170     0     0.0     ?  ?   \n","3  30.0  0.0  1.0      170  237   0       1     170     0     0.0     ?  ?   \n","4  31.0  0.0  2.0      100  219   0       1     150     0     0.0     ?  ?   \n","5  32.0  0.0  2.0      105  198   0       0     165     0     0.0     ?  ?   \n","6  32.0  1.0  2.0      110  225   0       0     184     0     0.0     ?  ?   \n","7  32.0  1.0  2.0      125  254   0       0     155     0     0.0     ?  ?   \n","8  33.0  1.0  3.0      120  298   0       0     185     0     0.0     ?  ?   \n","9  34.0  0.0  2.0      130  161   0       0     190     0     0.0     ?  ?   \n","\n","  thal  label  \n","0    ?      0  \n","1    ?      0  \n","2    ?      0  \n","3    6      0  \n","4    ?      0  \n","5    ?      0  \n","6    ?      0  \n","7    ?      0  \n","8    ?      0  \n","9    ?      0  "]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["combined_df.head(10)"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["age          0.000000\n","sex          0.000000\n","cp           0.000000\n","trestbps     6.413043\n","chol         3.260870\n","fbs          9.782609\n","restecg      0.217391\n","thalach      5.978261\n","exang        5.978261\n","oldpeak      6.739130\n","slope       33.586957\n","ca          66.413043\n","thal        52.826087\n","label        0.000000\n","dtype: float64\n"]}],"source":["# replace \"?\" with NaN, and then check the percentage of missing values for each feature. \n","\n","combined_df.replace('?', np.nan, inplace = True )\n","\n","missing_percentage = (combined_df.isnull().sum() / len(combined_df)) * 100\n","print(missing_percentage)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"ml_classification_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.20"}},"nbformat":4,"nbformat_minor":2}
