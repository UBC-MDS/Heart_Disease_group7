{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the presence of heart disease with key health metrics and attributes\n",
    "\n",
    "by Ethan Fang, Caroline Kahare and Alex Wong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "The objective of this project is to build a classification model that predicts the presence of heart disease based on key health metrics and attributes. It aims to contribute to the understanding and early detection of heart disease, which is crucial for effective medical intervention and prevention. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data \n",
    "\n",
    "The dataset is created by R. Detrano, A. Jánosi, W. Steinbrunn, M. Pfisterer, J. Schmid, S. Sandhu, K. Guppy, S. Lee, V. Froelicher and was sourced from UC Irvine's Machine Learning Repository. The original dataset consists of 920 observation and 76 attributes, however only 13 attributes were used for the project. The target variable, label, indicates the presence or absence of heart disease, with values ranging from 0 (no presence) to 4 (indicating varying levels of severity). The dataset also contains demographic, clinical, and diagnostic attributes, offering a comprehensive view of patient health metrics.\n",
    "\n",
    "Key features of the dataset include demographic indicators such as age (age in years) and sex (gender: 1 = male, 0 = female). Clinical measurements include trestbps (resting blood pressure), chol (serum cholesterol levels), thalach (maximum heart rate achieved), and oldpeak (ST depression induced by exercise). Additionally, categorical variables such as cp (chest pain type), fbs (fasting blood sugar > 120 mg/dl), restecg (resting electrocardiographic results), exang (exercise-induced angina), slope (slope of the peak exercise ST segment), ca (number of major vessels colored by fluoroscopy), and thal (heart imaging defects) provide valuable context for predicting heart disease. \n",
    "\n",
    "\n",
    "1. **age**: Age in years  \n",
    "2. **sex**: Sex  \n",
    "   - `1` = Male  \n",
    "   - `0` = Female  \n",
    "3. **cp**: Chest pain type  \n",
    "   - Value `1`: Typical angina  \n",
    "   - Value `2`: Atypical angina  \n",
    "   - Value `3`: Non-anginal pain  \n",
    "   - Value `4`: Asymptomatic  \n",
    "4. **trestbps**: Resting blood pressure (in mm Hg on admission to the hospital)  \n",
    "5. **chol**: Serum cholesterol in mg/dl  \n",
    "6. **fbs**: Fasting blood sugar (> 120 mg/dl)  \n",
    "   - `1` = True  \n",
    "   - `0` = False  \n",
    "7. **restecg**: Resting electrocardiographic results  \n",
    "   - Value `0`: Normal  \n",
    "   - Value `1`: Having ST-T wave abnormality (T wave inversions and/or ST  \n",
    "     elevation or depression of > 0.05 mV)  \n",
    "   - Value `2`: Showing probable or definite left ventricular hypertrophy by  \n",
    "     Estes' criteria  \n",
    "8. **thalach**: Maximum heart rate achieved  \n",
    "9. **exang**: Exercise-induced angina  \n",
    "   - `1` = Yes  \n",
    "   - `0` = No  \n",
    "10. **oldpeak**: ST depression induced by exercise relative to rest  \n",
    "11. **slope**: The slope of the peak exercise ST segment  \n",
    "    - Value `1`: Upsloping  \n",
    "    - Value `2`: Flat  \n",
    "    - Value `3`: Downsloping  \n",
    "12. **ca**: Number of major vessels (0-3) colored by fluoroscopy  \n",
    "13. **thal**:  \n",
    "    - `3` = Normal  \n",
    "    - `6` = Fixed defect  \n",
    "    - `7` = Reversible defect\n",
    "14. **label**: \n",
    "    - `0` = Absence \n",
    "    - `1` = Presence \n",
    "    - `2` = Presence\n",
    "    - `3` = Presence\n",
    "    - `4` = Presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair_ally as aly\n",
    "import altair as alt\n",
    "import pandera as pa\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from deepchecks.tabular import Dataset\n",
    "from deepchecks.tabular.checks import FeatureLabelCorrelation, FeatureFeatureCorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['age','sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120</td>\n",
       "      <td>243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>140</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170</td>\n",
       "      <td>237</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>127</td>\n",
       "      <td>333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>62.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>122</td>\n",
       "      <td>223</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>385</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>62.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>920 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp trestbps  chol fbs restecg thalach exang oldpeak slope  \\\n",
       "0    28.0  1.0  2.0      130   132   0       2     185     0     0.0   NaN   \n",
       "1    29.0  1.0  2.0      120   243   0       0     160     0     0.0   NaN   \n",
       "2    29.0  1.0  2.0      140  <NA>   0       0     170     0     0.0   NaN   \n",
       "3    30.0  0.0  1.0      170   237   0       1     170     0     0.0   NaN   \n",
       "4    31.0  0.0  2.0      100   219   0       1     150     0     0.0   NaN   \n",
       "..    ...  ...  ...      ...   ...  ..     ...     ...   ...     ...   ...   \n",
       "195  54.0  0.0  4.0      127   333   1       1     154     0       0   NaN   \n",
       "196  62.0  1.0  1.0     <NA>   139   0       1    <NA>  <NA>    <NA>   NaN   \n",
       "197  55.0  1.0  4.0      122   223   1       1     100     0       0   NaN   \n",
       "198  58.0  1.0  4.0     <NA>   385   1       2    <NA>  <NA>    <NA>   NaN   \n",
       "199  62.0  1.0  2.0      120   254   0       2      93     1       0   NaN   \n",
       "\n",
       "       ca  thal  label  \n",
       "0    <NA>  <NA>      0  \n",
       "1    <NA>  <NA>      0  \n",
       "2    <NA>  <NA>      0  \n",
       "3    <NA>     6      0  \n",
       "4    <NA>  <NA>      0  \n",
       "..    ...   ...    ...  \n",
       "195  <NA>  <NA>      1  \n",
       "196  <NA>  <NA>      0  \n",
       "197  <NA>     6      2  \n",
       "198  <NA>  <NA>      0  \n",
       "199  <NA>  <NA>      1  \n",
       "\n",
       "[920 rows x 14 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_hungarian = 'data/processed.hungarian.data'\n",
    "file_path_switzerland = 'data/processed.switzerland.data'\n",
    "file_path_cleveland = 'data/processed.cleveland.data'\n",
    "file_path_va = 'data/processed.va.data'\n",
    "hungary_df = pd.read_csv(file_path_hungarian,index_col=False, names = columns)\n",
    "swiss_df = pd.read_csv(file_path_switzerland,index_col=False, names = columns)\n",
    "cleveland_df = pd.read_csv(file_path_cleveland,index_col=False, names = columns)\n",
    "va_df = pd.read_csv(file_path_va,index_col=False, names = columns)\n",
    "\n",
    "# Combine the four dataset into one consolidated set \n",
    "combined_df = pd.concat([hungary_df, swiss_df, cleveland_df, va_df], axis = 0)\n",
    "combined_df.replace(\"?\", pd.NA, inplace = True)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File is in the expected format.\n"
     ]
    }
   ],
   "source": [
    "## --- 1. Correct data file format\n",
    "\n",
    "file_path = [file_path_hungarian, file_path_switzerland, file_path_cleveland, file_path_va]\n",
    "if False in [path.endswith('.data') for path in file_path]:\n",
    "    print(\"Warning: The file extension is not .data\")\n",
    "else:\n",
    "    print(\"File is in the expected format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are correct.\n"
     ]
    }
   ],
   "source": [
    "## --- 2. Correct column names\n",
    "\n",
    "expected_names = set(columns)\n",
    "actual_names = set(combined_df.columns)\n",
    "if expected_names != actual_names:\n",
    "    print(f\"Warning: Column names do not match. Expected: {columns}, Found: {combined_df.columns.tolist()}\")\n",
    "else:\n",
    "    print(\"Column names are correct.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing row found.\n"
     ]
    }
   ],
   "source": [
    "## --- 3. No empty observations\n",
    "\n",
    "empty_obs_schema = pa.DataFrameSchema(\n",
    "    checks = [\n",
    "        pa.Check(lambda df: ~(df.isna().all(axis = 1)).any(), error = \"Empty rows found.\")\n",
    "    ]\n",
    ")\n",
    "try:\n",
    "    empty_obs_schema.validate(combined_df)\n",
    "    print(\"No missing row found.\")\n",
    "except pa.errors.SchemaError as a:\n",
    "    print(f\"Warning: There are {combined_df.isna().sum().sum()} missing values in dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'age' passed the test of missingness.\n",
      "Column 'sex' passed the test of missingness.\n",
      "Column 'cp' passed the test of missingness.\n",
      "Column 'trestbps' passed the test of missingness.\n",
      "Column 'chol' passed the test of missingness.\n",
      "Column 'fbs' passed the test of missingness.\n",
      "Column 'restecg' passed the test of missingness.\n",
      "Column 'thalach' passed the test of missingness.\n",
      "Column 'exang' passed the test of missingness.\n",
      "Column 'oldpeak' passed the test of missingness.\n",
      "Column 'slope' passed the test of missingness.\n",
      "Column 'ca' passed the test of missingness.\n",
      "Column 'thal' passed the test of missingness.\n",
      "Column 'label' passed the test of missingness.\n"
     ]
    }
   ],
   "source": [
    "## --- 4. Missingness not beyond expected threshold\n",
    "\n",
    "threshold = 0.05\n",
    "missing_prop = combined_df.isna().mean()\n",
    "for col, prop in missing_prop.items():\n",
    "    if prop > threshold:\n",
    "        print(f\"Warning: There're too many missing values in column '{col}'.\")\n",
    "    else:\n",
    "        print(f\"Column '{col}' passed the test of missingness.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Validation failed: expected series 'age' to have type int64, got float64\n"
     ]
    }
   ],
   "source": [
    "## --- 5. Correct data types in each column\n",
    "\n",
    "column_type_schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"age\": pa.Column(pa.Int, nullable = True),\n",
    "        \"sex\": pa.Column(pa.Int, nullable = True),\n",
    "        \"cp\": pa.Column(pa.String, nullable = True),\n",
    "        \"trestbps\": pa.Column(pa.Int, nullable = True),\n",
    "        \"chol\": pa.Column(pa.Int, nullable = True),\n",
    "        \"fbs\": pa.Column(pa.Int, nullable = True),\n",
    "        \"restecg\": pa.Column(pa.String, nullable = True),\n",
    "        \"thalach\": pa.Column(pa.Int, nullable = True),\n",
    "        \"exang\": pa.Column(pa.String, nullable = True),\n",
    "        \"oldpeak\": pa.Column(pa.Float, nullable = True),\n",
    "        \"slope\": pa.Column(pa.String, nullable = True),\n",
    "        \"ca\": pa.Column(pa.Float, nullable = True),\n",
    "        \"thal\": pa.Column(pa.String, nullable = True),\n",
    "        \"label\": pa.Column(pa.Int, nullable = True)\n",
    "    }    \n",
    ")\n",
    "try:\n",
    "    column_type_schema.validate(combined_df)\n",
    "    print(\"All columns have correct data types.\")\n",
    "except pa.errors.SchemaError as e:\n",
    "    print(f\"Warning: Validation failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: There're duplicate row: \n",
      "      age  sex   cp trestbps chol fbs restecg thalach exang oldpeak slope ca  \\\n",
      "101  49.0  0.0  2.0      110    ?   0       0     160     0     0.0     ?  ?   \n",
      "102  49.0  0.0  2.0      110    ?   0       0     160     0     0.0     ?  ?   \n",
      "139  58.0  1.0  3.0      150  219   0       1     118     1       0     ?  ?   \n",
      "187  58.0  1.0  3.0      150  219   0       1     118     1       0     ?  ?   \n",
      "\n",
      "    thal  label  \n",
      "101    ?      0  \n",
      "102    ?      0  \n",
      "139    ?      2  \n",
      "187    ?      2  .\n"
     ]
    }
   ],
   "source": [
    "## --- 6. No duplicate observations\n",
    "\n",
    "duplicate_obs_schema = pa.DataFrameSchema(\n",
    "    checks=[\n",
    "        pa.Check(lambda df: ~df.duplicated().any(), error=\"There're duplicate rows\")\n",
    "    ]\n",
    ")\n",
    "try:\n",
    "    duplicate_obs_schema.validate(combined_df)\n",
    "    print(\"No duplicate rows found.\")\n",
    "except pa.errors.SchemaError as e:\n",
    "    duplicate_rows = combined_df[combined_df.duplicated(keep=False)]\n",
    "    print(f\"Warning: There're duplicate rows: \\n{duplicate_rows}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: There're outlier or anomalous values.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g9/lxkj9z6535n7rv9brs64ytn40000gn/T/ipykernel_51579/1686152220.py:21: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  replicate_df = combined_df.applymap(lambda x: float(x) if pd.notnull(x) else x)\n"
     ]
    }
   ],
   "source": [
    "## --- 7. No outlier or anomalous values\n",
    "\n",
    "values_schema = pa.DataFrameSchema({\n",
    "    \"age\": pa.Column(float, pa.Check.between(0, 120), nullable=True),\n",
    "    \"sex\": pa.Column(float, pa.Check.isin([0.0, 1.0]), nullable=True), \n",
    "    \"cp\": pa.Column(float, pa.Check.isin([1.0, 2.0, 3.0, 4.0]), nullable=True), \n",
    "    \"trestbps\": pa.Column(float, pa.Check.between(20, 220), nullable=True),\n",
    "    \"chol\": pa.Column(float, pa.Check.between(50, 800), nullable=True), \n",
    "    \"fbs\": pa.Column(float, pa.Check.isin([0.0, 1.0]), nullable=True), \n",
    "    \"restecg\": pa.Column(float, pa.Check.isin([0.0, 1.0, 2.0]), nullable=True),  \n",
    "    \"thalach\": pa.Column(float, pa.Check.between(50, 240), nullable=True),  \n",
    "    \"exang\":  pa.Column(float, pa.Check.isin([0.0, 1.0]), nullable=True),  \n",
    "    \"oldpeak\": pa.Column(float, pa.Check.between(0.0, 7.0), nullable=True),  \n",
    "    \"slope\": pa.Column(float, pa.Check.isin([1.0, 2.0, 3.0]), nullable=True),  \n",
    "    \"ca\": pa.Column(float, pa.Check.between(0, 4), nullable=True), \n",
    "    \"thal\": pa.Column(float, pa.Check.isin([3.0, 6.0, 7.0]), nullable=True),  \n",
    "    \"label\": pa.Column(float, pa.Check.between(0.0, 4.0), nullable=True),  \n",
    "})\n",
    "replicate_df = combined_df.applymap(lambda x: float(x) if pd.notnull(x) else x)\n",
    "try:\n",
    "    values_schema.validate(replicate_df, lazy = True)\n",
    "    print(\"No outlier or anomalous value found.\")\n",
    "except pa.errors.SchemaErrors as e:\n",
    "    print(f\"Warning: There're outlier or anomalous values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- 8. There's no categorical value in this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class proportions are label\n",
      "0    0.446739\n",
      "1    0.288043\n",
      "2    0.118478\n",
      "3    0.116304\n",
      "4    0.030435\n",
      "Name: proportion, dtype: float64\n",
      "Class proportions are as expected.\n"
     ]
    }
   ],
   "source": [
    "## --- 9. Target/response variable follows expected distribution\n",
    "\n",
    "proportions = combined_df.label.value_counts(normalize=True)\n",
    "print(\"Class proportions are\", proportions)\n",
    "print(\"Class proportions are as expected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fangziming/miniforge3/envs/hd_new/lib/python3.11/site-packages/deepchecks/tabular/dataset.py:236: UserWarning:\n",
      "\n",
      "Dataframe index has duplicate indexes, setting index to [0,1..,n-1].\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5418eed9740945588d04ac7362fd135b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h4><b>Feature Label Correlation</b></h4>'), HTML(value='<p>Return the PPS (Predict…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is fine.\n"
     ]
    }
   ],
   "source": [
    "## --- 10. No anomalous correlations between target variable and features variables\n",
    "\n",
    "features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
    "ds = Dataset(combined_df, label='label', cat_features=categorical_features)\n",
    "\n",
    "check_feat_lab_corr = FeatureLabelCorrelation().add_condition_feature_pps_less_than(0.9)\n",
    "check_feat_lab_corr_result = check_feat_lab_corr.run(dataset=ds)\n",
    "check_feat_lab_corr.run(dataset=ds).show()\n",
    "if not check_feat_lab_corr_result.passed_conditions():\n",
    "    raise ValueError(\"The correlation between target and features variables exceeds the threshold.\")\n",
    "else:\n",
    "    print(\"Everything is fine.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a2cc861285047268ed179268d722505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h4><b>Feature-Feature Correlation</b></h4>'), HTML(value='<p>    Checks for pairwi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is fine.\n"
     ]
    }
   ],
   "source": [
    "## --- 11. No anomalous correlations between features variables\n",
    "\n",
    "check_feat_feat_corr = FeatureFeatureCorrelation(threshold=0.9)\n",
    "check_feat_feat_corr_result = check_feat_feat_corr.run(dataset=ds)\n",
    "check_feat_feat_corr.run(dataset=ds).show()\n",
    "\n",
    "if not check_feat_feat_corr_result.passed_conditions():\n",
    "    raise ValueError(\"The correlation between features variables exceeds the threshold.\")\n",
    "else:\n",
    "    print(\"Everything is fine.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120</td>\n",
       "      <td>243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>140</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170</td>\n",
       "      <td>237</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>127</td>\n",
       "      <td>333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>62.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>122</td>\n",
       "      <td>223</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>385</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>62.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>913 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp trestbps  chol fbs restecg thalach exang oldpeak slope  \\\n",
       "0    28.0  1.0  2.0      130   132   0       2     185     0     0.0  <NA>   \n",
       "1    29.0  1.0  2.0      120   243   0       0     160     0     0.0  <NA>   \n",
       "2    29.0  1.0  2.0      140  <NA>   0       0     170     0     0.0  <NA>   \n",
       "3    30.0  0.0  1.0      170   237   0       1     170     0     0.0  <NA>   \n",
       "4    31.0  0.0  2.0      100   219   0       1     150     0     0.0  <NA>   \n",
       "..    ...  ...  ...      ...   ...  ..     ...     ...   ...     ...   ...   \n",
       "908  54.0  0.0  4.0      127   333   1       1     154     0       0  <NA>   \n",
       "909  62.0  1.0  1.0     <NA>   139   0       1    <NA>  <NA>    <NA>  <NA>   \n",
       "910  55.0  1.0  4.0      122   223   1       1     100     0       0  <NA>   \n",
       "911  58.0  1.0  4.0     <NA>   385   1       2    <NA>  <NA>    <NA>  <NA>   \n",
       "912  62.0  1.0  2.0      120   254   0       2      93     1       0  <NA>   \n",
       "\n",
       "       ca  thal  label  \n",
       "0    <NA>  <NA>      0  \n",
       "1    <NA>  <NA>      0  \n",
       "2    <NA>  <NA>      0  \n",
       "3    <NA>     6      0  \n",
       "4    <NA>  <NA>      0  \n",
       "..    ...   ...    ...  \n",
       "908  <NA>  <NA>      1  \n",
       "909  <NA>  <NA>      0  \n",
       "910  <NA>     6      2  \n",
       "911  <NA>  <NA>      0  \n",
       "912  <NA>  <NA>      1  \n",
       "\n",
       "[913 rows x 14 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## delete duplicated rows\n",
    "duplicate_index = [102,187]\n",
    "combined_df = combined_df.drop(index=duplicate_index).reset_index(drop=True)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis\n",
    "\n",
    "#### Key findings\n",
    "\n",
    "- Patients with no heart disease exhibits on average higher ST depression induced by exercise relative to rest, higher maximum heart rate and lower serum cholestorel. \n",
    "\n",
    "- Heart disease is more common among patients over 55. \n",
    "\n",
    "- Patients with heart disease are more likely to experience asymptomatic chest pains.\n",
    "\n",
    "- Males appear to be more susceptible to heart disease. \n",
    "\n",
    "- Patients without heart disease tend to have lower fasting blood sugar when compared to the positive group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(combined_df, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pyarrow' has no attribute 'from_pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/hd_new/lib/python3.11/site-packages/IPython/core/formatters.py:1036\u001b[0m, in \u001b[0;36mMimeBundleFormatter.__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m   1033\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[1;32m   1035\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1036\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/hd_new/lib/python3.11/site-packages/altair/vegalite/v5/api.py:3682\u001b[0m, in \u001b[0;36mTopLevelMixin._repr_mimebundle_\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m   3680\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3681\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer \u001b[38;5;241m:=\u001b[39m renderers\u001b[38;5;241m.\u001b[39mget():\n\u001b[0;32m-> 3682\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdct\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/hd_new/lib/python3.11/site-packages/altair/utils/display.py:232\u001b[0m, in \u001b[0;36mHTMLRenderer.__call__\u001b[0;34m(self, spec, **metadata)\u001b[0m\n\u001b[1;32m    230\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    231\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmetadata, output_div\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_div)\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mspec_to_mimebundle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhtml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/hd_new/lib/python3.11/site-packages/altair/utils/mimebundle.py:129\u001b[0m, in \u001b[0;36mspec_to_mimebundle\u001b[0;34m(spec, format, mode, vega_version, vegaembed_version, vegalite_version, embed_options, engine, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m internal_mode: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvega-lite\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvega\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_vegafusion():\n\u001b[0;32m--> 129\u001b[0m     spec \u001b[38;5;241m=\u001b[39m \u001b[43mcompile_with_vegafusion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     internal_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvega\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Default to the embed options set by alt.renderers.set_embed_options\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/hd_new/lib/python3.11/site-packages/altair/utils/_vegafusion_data.py:273\u001b[0m, in \u001b[0;36mcompile_with_vegafusion\u001b[0;34m(vegalite_spec)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;66;03m# Pre-evaluate transforms in vega spec with vegafusion\u001b[39;00m\n\u001b[1;32m    272\u001b[0m row_limit \u001b[38;5;241m=\u001b[39m data_transformers\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_rows\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 273\u001b[0m transformed_vega_spec, warnings \u001b[38;5;241m=\u001b[39m \u001b[43mvf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mruntime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_transform_spec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvega_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_local_tz\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43minline_datasets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minline_tables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrow_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m# Check from row limit warning and convert to MaxRowsError\u001b[39;00m\n\u001b[1;32m    281\u001b[0m handle_row_limit_exceeded(row_limit, warnings)\n",
      "File \u001b[0;32m~/miniforge3/envs/hd_new/lib/python3.11/site-packages/vegafusion/runtime.py:408\u001b[0m, in \u001b[0;36mVegaFusionRuntime.pre_transform_spec\u001b[0;34m(self, spec, local_tz, default_input_tz, row_limit, preserve_interactivity, inline_datasets, keep_signals, keep_datasets)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03mEvaluate supported transforms in an input Vega specification\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;124;03m        were eligible for pre-transforming\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    407\u001b[0m local_tz \u001b[38;5;241m=\u001b[39m local_tz \u001b[38;5;129;01mor\u001b[39;00m get_local_tz()\n\u001b[0;32m--> 408\u001b[0m imported_inline_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_import_inline_datasets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43minline_datasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_inline_column_usage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m new_spec, warnings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mruntime\u001b[38;5;241m.\u001b[39mpre_transform_spec(\n\u001b[1;32m    413\u001b[0m     spec,\n\u001b[1;32m    414\u001b[0m     local_tz\u001b[38;5;241m=\u001b[39mlocal_tz,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    420\u001b[0m     keep_datasets\u001b[38;5;241m=\u001b[39mparse_variables(keep_datasets),\n\u001b[1;32m    421\u001b[0m )\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_spec, warnings\n",
      "File \u001b[0;32m~/miniforge3/envs/hd_new/lib/python3.11/site-packages/vegafusion/runtime.py:303\u001b[0m, in \u001b[0;36mVegaFusionRuntime._import_inline_datasets\u001b[0;34m(self, inline_datasets, inline_dataset_usage)\u001b[0m\n\u001b[1;32m    300\u001b[0m         imported_inline_datasets[name] \u001b[38;5;241m=\u001b[39m Table(inner_value)\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;66;03m# Older pandas, convert through pyarrow\u001b[39;00m\n\u001b[0;32m--> 303\u001b[0m         imported_inline_datasets[name] \u001b[38;5;241m=\u001b[39m Table(\u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m(inner_value))\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;66;03m# Let narwhals import the dict using a default backend\u001b[39;00m\n\u001b[1;32m    306\u001b[0m     df_nw \u001b[38;5;241m=\u001b[39m nw\u001b[38;5;241m.\u001b[39mfrom_dict(value, native_namespace\u001b[38;5;241m=\u001b[39m_get_default_namespace())\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pyarrow' has no attribute 'from_pandas'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "alt.ConcatChart(...)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aly.alt.data_transformers.enable('vegafusion')\n",
    "aly.dist(train_df, color='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pyarrow' has no attribute 'from_pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/hd_new/lib/python3.11/site-packages/IPython/core/formatters.py:1036\u001b[0m, in \u001b[0;36mMimeBundleFormatter.__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m   1033\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[1;32m   1035\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1036\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/hd_new/lib/python3.11/site-packages/altair/vegalite/v5/api.py:3682\u001b[0m, in \u001b[0;36mTopLevelMixin._repr_mimebundle_\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m   3680\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3681\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer \u001b[38;5;241m:=\u001b[39m renderers\u001b[38;5;241m.\u001b[39mget():\n\u001b[0;32m-> 3682\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdct\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/hd_new/lib/python3.11/site-packages/altair/utils/display.py:232\u001b[0m, in \u001b[0;36mHTMLRenderer.__call__\u001b[0;34m(self, spec, **metadata)\u001b[0m\n\u001b[1;32m    230\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    231\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmetadata, output_div\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_div)\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mspec_to_mimebundle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhtml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/hd_new/lib/python3.11/site-packages/altair/utils/mimebundle.py:129\u001b[0m, in \u001b[0;36mspec_to_mimebundle\u001b[0;34m(spec, format, mode, vega_version, vegaembed_version, vegalite_version, embed_options, engine, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m internal_mode: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvega-lite\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvega\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_vegafusion():\n\u001b[0;32m--> 129\u001b[0m     spec \u001b[38;5;241m=\u001b[39m \u001b[43mcompile_with_vegafusion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     internal_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvega\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Default to the embed options set by alt.renderers.set_embed_options\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/hd_new/lib/python3.11/site-packages/altair/utils/_vegafusion_data.py:273\u001b[0m, in \u001b[0;36mcompile_with_vegafusion\u001b[0;34m(vegalite_spec)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;66;03m# Pre-evaluate transforms in vega spec with vegafusion\u001b[39;00m\n\u001b[1;32m    272\u001b[0m row_limit \u001b[38;5;241m=\u001b[39m data_transformers\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_rows\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 273\u001b[0m transformed_vega_spec, warnings \u001b[38;5;241m=\u001b[39m \u001b[43mvf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mruntime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_transform_spec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvega_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_local_tz\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43minline_datasets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minline_tables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrow_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m# Check from row limit warning and convert to MaxRowsError\u001b[39;00m\n\u001b[1;32m    281\u001b[0m handle_row_limit_exceeded(row_limit, warnings)\n",
      "File \u001b[0;32m~/miniforge3/envs/hd_new/lib/python3.11/site-packages/vegafusion/runtime.py:408\u001b[0m, in \u001b[0;36mVegaFusionRuntime.pre_transform_spec\u001b[0;34m(self, spec, local_tz, default_input_tz, row_limit, preserve_interactivity, inline_datasets, keep_signals, keep_datasets)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03mEvaluate supported transforms in an input Vega specification\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;124;03m        were eligible for pre-transforming\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    407\u001b[0m local_tz \u001b[38;5;241m=\u001b[39m local_tz \u001b[38;5;129;01mor\u001b[39;00m get_local_tz()\n\u001b[0;32m--> 408\u001b[0m imported_inline_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_import_inline_datasets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43minline_datasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_inline_column_usage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m new_spec, warnings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mruntime\u001b[38;5;241m.\u001b[39mpre_transform_spec(\n\u001b[1;32m    413\u001b[0m     spec,\n\u001b[1;32m    414\u001b[0m     local_tz\u001b[38;5;241m=\u001b[39mlocal_tz,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    420\u001b[0m     keep_datasets\u001b[38;5;241m=\u001b[39mparse_variables(keep_datasets),\n\u001b[1;32m    421\u001b[0m )\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_spec, warnings\n",
      "File \u001b[0;32m~/miniforge3/envs/hd_new/lib/python3.11/site-packages/vegafusion/runtime.py:303\u001b[0m, in \u001b[0;36mVegaFusionRuntime._import_inline_datasets\u001b[0;34m(self, inline_datasets, inline_dataset_usage)\u001b[0m\n\u001b[1;32m    300\u001b[0m         imported_inline_datasets[name] \u001b[38;5;241m=\u001b[39m Table(inner_value)\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;66;03m# Older pandas, convert through pyarrow\u001b[39;00m\n\u001b[0;32m--> 303\u001b[0m         imported_inline_datasets[name] \u001b[38;5;241m=\u001b[39m Table(\u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m(inner_value))\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;66;03m# Let narwhals import the dict using a default backend\u001b[39;00m\n\u001b[1;32m    306\u001b[0m     df_nw \u001b[38;5;241m=\u001b[39m nw\u001b[38;5;241m.\u001b[39mfrom_dict(value, native_namespace\u001b[38;5;241m=\u001b[39m_get_default_namespace())\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pyarrow' has no attribute 'from_pandas'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "alt.ConcatChart(...)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aly.dist(train_df, dtype = 'object', color = 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=[\"label\"])\n",
    "X_test = test_df.drop(columns=[\"label\"])\n",
    "y_train = train_df[\"label\"]\n",
    "y_test = test_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak'] # standard scaling for numerical features\n",
    "categorical_features = ['cp', 'restecg'] # onehot encoding for categorical features with > 2 classes\n",
    "binary_features = ['sex', 'exang', 'fbs'] # simple imputing on the binary features\n",
    "drop_features = ['thal', 'ca', 'slope'] # dropping features with signifcant NaN values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer_pipe = make_pipeline(SimpleImputer(strategy = 'median'), StandardScaler())\n",
    "categorical_transfomer_pipe = make_pipeline(SimpleImputer(strategy = 'most_frequent'), OneHotEncoder(drop = 'if_binary', sparse_output = False)) \n",
    "imputer = SimpleImputer(strategy = 'most_frequent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer_pipe, numeric_features),\n",
    "    (categorical_transfomer_pipe, categorical_features),\n",
    "    (imputer, binary_features),\n",
    "    (\"drop\", drop_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ( \n",
    "    numeric_features +\n",
    "    preprocessor.named_transformers_['pipeline-2'].get_feature_names_out().tolist() + \n",
    "    binary_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>cp_1.0</th>\n",
       "      <th>cp_2.0</th>\n",
       "      <th>cp_3.0</th>\n",
       "      <th>cp_4.0</th>\n",
       "      <th>restecg_0.0</th>\n",
       "      <th>restecg_1.0</th>\n",
       "      <th>restecg_2.0</th>\n",
       "      <th>sex</th>\n",
       "      <th>exang</th>\n",
       "      <th>fbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.806021</td>\n",
       "      <td>-0.1196</td>\n",
       "      <td>0.178542</td>\n",
       "      <td>-1.048509</td>\n",
       "      <td>-1.048509</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.046673</td>\n",
       "      <td>-0.660108</td>\n",
       "      <td>0.402221</td>\n",
       "      <td>-1.12703</td>\n",
       "      <td>-1.12703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.325714</td>\n",
       "      <td>0.961415</td>\n",
       "      <td>-1.890497</td>\n",
       "      <td>-1.205551</td>\n",
       "      <td>-1.205551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.059914</td>\n",
       "      <td>0.420908</td>\n",
       "      <td>0.122622</td>\n",
       "      <td>0.129303</td>\n",
       "      <td>0.129303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.085061</td>\n",
       "      <td>-0.1196</td>\n",
       "      <td>-0.389978</td>\n",
       "      <td>2.013803</td>\n",
       "      <td>2.013803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>-0.592847</td>\n",
       "      <td>-0.1196</td>\n",
       "      <td>0.392901</td>\n",
       "      <td>0.835991</td>\n",
       "      <td>0.835991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>-0.379674</td>\n",
       "      <td>0.691162</td>\n",
       "      <td>-1.890497</td>\n",
       "      <td>0.011522</td>\n",
       "      <td>0.011522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>0.79278</td>\n",
       "      <td>-0.1196</td>\n",
       "      <td>-1.890497</td>\n",
       "      <td>-2.422623</td>\n",
       "      <td>-2.422623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>0.47302</td>\n",
       "      <td>2.042431</td>\n",
       "      <td>-1.890497</td>\n",
       "      <td>-1.323332</td>\n",
       "      <td>-1.323332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>-1.019194</td>\n",
       "      <td>-1.308717</td>\n",
       "      <td>-0.576378</td>\n",
       "      <td>1.424897</td>\n",
       "      <td>1.424897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>644 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age  trestbps      chol   thalach   oldpeak cp_1.0 cp_2.0 cp_3.0  \\\n",
       "0   -0.806021   -0.1196  0.178542 -1.048509 -1.048509    0.0    0.0    0.0   \n",
       "1    0.046673 -0.660108  0.402221  -1.12703  -1.12703    0.0    1.0    0.0   \n",
       "2    1.325714  0.961415 -1.890497 -1.205551 -1.205551    0.0    0.0    0.0   \n",
       "3   -0.059914  0.420908  0.122622  0.129303  0.129303    0.0    1.0    0.0   \n",
       "4   -2.085061   -0.1196 -0.389978  2.013803  2.013803    0.0    1.0    0.0   \n",
       "..        ...       ...       ...       ...       ...    ...    ...    ...   \n",
       "639 -0.592847   -0.1196  0.392901  0.835991  0.835991    0.0    1.0    0.0   \n",
       "640 -0.379674  0.691162 -1.890497  0.011522  0.011522    0.0    0.0    0.0   \n",
       "641   0.79278   -0.1196 -1.890497 -2.422623 -2.422623    0.0    0.0    0.0   \n",
       "642   0.47302  2.042431 -1.890497 -1.323332 -1.323332    0.0    0.0    0.0   \n",
       "643 -1.019194 -1.308717 -0.576378  1.424897  1.424897    0.0    0.0    1.0   \n",
       "\n",
       "    cp_4.0 restecg_0.0 restecg_1.0 restecg_2.0  sex exang  fbs  \n",
       "0      1.0         1.0         0.0         0.0  1.0   0.0  0.0  \n",
       "1      0.0         1.0         0.0         0.0  1.0   0.0  0.0  \n",
       "2      1.0         1.0         0.0         0.0  1.0   1.0  0.0  \n",
       "3      0.0         1.0         0.0         0.0  0.0   1.0  0.0  \n",
       "4      0.0         1.0         0.0         0.0  0.0   0.0  0.0  \n",
       "..     ...         ...         ...         ...  ...   ...  ...  \n",
       "639    0.0         1.0         0.0         0.0  1.0   0.0  0.0  \n",
       "640    1.0         1.0         0.0         0.0  1.0   1.0  0.0  \n",
       "641    1.0         1.0         0.0         0.0  1.0   0.0  0.0  \n",
       "642    1.0         0.0         1.0         0.0  1.0   1.0  0.0  \n",
       "643    0.0         1.0         0.0         0.0  0.0   0.0  0.0  \n",
       "\n",
       "[644 rows x 15 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed = pd.DataFrame(X_train_transformed, columns = col_names)\n",
    "X_test_transformed = pd.DataFrame(X_test_transformed, columns = col_names)\n",
    "X_train_transformed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning models application and hyperparameters tuning\n",
    "#### Summary\n",
    "\n",
    "- Various machine learning models were tested and optimized using hyperparameter tuning to identify the best-performing model.\n",
    "- Randomized Search CV was used to perform hyperparameter optimization for each model. Key parameters tuned include:\n",
    "   - Logistic Regression: Regularization strength(C), Solver(liblinear, lbfgs).\n",
    "   - Decision Tree: Maximum depth, Minimum samples per split.\n",
    "   - SVM: Regularization strength(C), Kernel type(linear, rbf).\n",
    "   - KNN: Number of neighbours, Weight type(uniform, distance).\n",
    "\n",
    "- Results:\n",
    "\n",
    "    <img src=\"docs/Best_Models.png\" alt=\"Model Summary Table\" width=\"800\"/>\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "- The K-Nearest Neighbors (KNN) model emerged as the best-performing classifier based on accuracy and weighted F1-score. Despite moderate overall performance, it provided reasonable balance across classes compared to other models.This study demonstrates the potential of leveraging machine learning techniques for predicting heart disease but also highlights the challenges posed by multi-class classification and limited data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#pio.templates.default = \"plotly_white\"\n",
    "\n",
    "#%matplotlib inline\n",
    "\n",
    "#Models for scikit learn\n",
    "\n",
    "#Model Evaluations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state = 123, max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Support Vector Machine': SVC(random_state = 123, probability=True),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "param_distributions = {\n",
    "    'Logistic Regression': {\n",
    "        'classifier__C': stats.loguniform(1e-3, 1e3),\n",
    "        'classifier__solver': ['liblinear', 'lbfgs']\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'classifier__max_depth': [3, 5, 10],\n",
    "        'classifier__min_samples_split': stats.randint(2, 20)\n",
    "    },\n",
    "    'Support Vector Machine': {\n",
    "        'classifier__C': stats.loguniform(1e-2, 1e2),\n",
    "        'classifier__kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    'K-Nearest Neighbors': {\n",
    "        'classifier__n_neighbors': stats.randint(3, 20),\n",
    "        'classifier__weights': ['uniform', 'distance']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning hyperparameters for Logistic Regression using RandomizedSearchCV...\n",
      "Best parameters for Logistic Regression: {'classifier__C': np.float64(0.1767016940294795), 'classifier__solver': 'liblinear'}\n",
      "----------------------------------------\n",
      "Tuning hyperparameters for Decision Tree using RandomizedSearchCV...\n",
      "Best parameters for Decision Tree: {'classifier__max_depth': 10, 'classifier__min_samples_split': 16}\n",
      "----------------------------------------\n",
      "Tuning hyperparameters for Support Vector Machine using RandomizedSearchCV...\n",
      "Best parameters for Support Vector Machine: {'classifier__C': np.float64(0.31489116479568624), 'classifier__kernel': 'linear'}\n",
      "----------------------------------------\n",
      "Tuning hyperparameters for K-Nearest Neighbors using RandomizedSearchCV...\n",
      "Best parameters for K-Nearest Neighbors: {'classifier__n_neighbors': 9, 'classifier__weights': 'distance'}\n",
      "----------------------------------------\n",
      "Evaluating Logistic Regression on test set...\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.89      0.79       119\n",
      "           1       0.43      0.59      0.50        81\n",
      "           2       0.11      0.03      0.04        37\n",
      "           3       0.14      0.03      0.05        33\n",
      "           4       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.57       276\n",
      "   macro avg       0.28      0.31      0.28       276\n",
      "weighted avg       0.47      0.57      0.50       276\n",
      "\n",
      "Confusion Matrix:\n",
      "[[106  11   2   0   0]\n",
      " [ 26  48   3   4   0]\n",
      " [ 10  24   1   2   0]\n",
      " [  5  24   3   1   0]\n",
      " [  2   4   0   0   0]]\n",
      "----------------------------------------\n",
      "Evaluating Decision Tree on test set...\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.71      0.75       119\n",
      "           1       0.40      0.43      0.41        81\n",
      "           2       0.24      0.27      0.26        37\n",
      "           3       0.19      0.21      0.20        33\n",
      "           4       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.50       276\n",
      "   macro avg       0.33      0.33      0.32       276\n",
      "weighted avg       0.51      0.50      0.50       276\n",
      "\n",
      "Confusion Matrix:\n",
      "[[85 23  5  5  1]\n",
      " [14 35 15 17  0]\n",
      " [ 5 15 10  6  1]\n",
      " [ 3 14  8  7  1]\n",
      " [ 0  1  3  2  0]]\n",
      "----------------------------------------\n",
      "Evaluating Support Vector Machine on test set...\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.75       119\n",
      "           1       0.40      0.79      0.53        81\n",
      "           2       0.00      0.00      0.00        37\n",
      "           3       0.00      0.00      0.00        33\n",
      "           4       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.55       276\n",
      "   macro avg       0.23      0.31      0.26       276\n",
      "weighted avg       0.44      0.55      0.48       276\n",
      "\n",
      "Confusion Matrix:\n",
      "[[88 31  0  0  0]\n",
      " [17 64  0  0  0]\n",
      " [ 6 31  0  0  0]\n",
      " [ 5 28  0  0  0]\n",
      " [ 1  5  0  0  0]]\n",
      "----------------------------------------\n",
      "Evaluating K-Nearest Neighbors on test set...\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.78       119\n",
      "           1       0.46      0.47      0.46        81\n",
      "           2       0.29      0.32      0.31        37\n",
      "           3       0.33      0.21      0.26        33\n",
      "           4       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.55       276\n",
      "   macro avg       0.37      0.36      0.36       276\n",
      "weighted avg       0.54      0.55      0.55       276\n",
      "\n",
      "Confusion Matrix:\n",
      "[[96 17  4  2  0]\n",
      " [19 38 15  8  1]\n",
      " [ 4 14 12  4  3]\n",
      " [ 5 12  8  7  1]\n",
      " [ 2  2  2  0  0]]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_models = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Tuning hyperparameters for {model_name} using RandomizedSearchCV...\")\n",
    "    \n",
    "    clf = Pipeline(steps=[('classifier', model)])\n",
    "    \n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=clf,\n",
    "        param_distributions=param_distributions[model_name],\n",
    "        scoring=make_scorer(roc_auc_score, needs_proba=True),\n",
    "        n_iter=10, \n",
    "        cv=5,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    random_search.fit(X_train_transformed, y_train)\n",
    "    \n",
    "    best_models[model_name] = random_search.best_estimator_\n",
    "    \n",
    "    print(f\"Best parameters for {model_name}: {random_search.best_params_}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "for model_name, model in best_models.items():\n",
    "    print(f\"Evaluating {model_name} on test set...\")\n",
    "    y_pred = model.predict(X_test_transformed)\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "{bibliography}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hd_new] *",
   "language": "python",
   "name": "conda-env-hd_new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
